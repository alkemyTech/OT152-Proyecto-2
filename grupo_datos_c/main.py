import logging.config
from functools import reduce

import defusedxml.ElementTree as ETree
from decouple import config as cfg

from modules import bodies_with_answer_count, count_words_in_body, generate_data_dict, get_bodies_and_answer_counts,\
                    get_tags_and_ansid, get_tags_with_acc_answ, get_user_favcount, split_and_count_tags


# Load logging configurations
logging.config.fileConfig(cfg('FILE_PATH'))
# Instansiate logger class
logger = logging.getLogger('Grupo_Datos_C')


def read_xml():
    """
    Loads xml file to process

            Returns: xml Element Tree
    """
    file_xml = ETree.parse('posts.xml')
    return file_xml.getroot()


def chunkify(data, chunk_size=1000):
    """
    Returns a generator with the information necesary to iterate and process data

            Parameters:
                    data (xml.etree.ElementTree.Element): contains data read from xml file
                    chunk_size (int): number of data to process for each chunk
            Returns:
                    generator: contains part of that to process based on the selected chunk_size
    """
    data_lenght = len(data)

    for i in range(0, data_lenght, chunk_size):
        yield data.findall('row')[i: i + chunk_size]


def mapped_chunks_top10_tags(chunks):
    """
    Returns a map object with dictionaries containing count of tags with accepted answer for each chunk
            Parameter chunks(generator):
                    chunk of data to process
            Returns:
                    mapped (list): contains Counter dictionaries objects with tags with accepted answer for each chunk
    """
    mapped = map(get_tags_and_ansid, chunks)
    mapped = map(get_tags_with_acc_answ, mapped)
    mapped = map(split_and_count_tags, mapped)
    return mapped


def reducer_top10_tags(list_of_dict_1, list_of_dict_2):
    """
    Returns the sum of all lists of Counter dictionaries to get total of each tag with an accepted answer per chunk

            Parametes:
                    list_of_dict_1 (list): list of Counter objects generated per chunk
                    list_of_dict_2 (list): list of Counter objects generated per chunk
            Returns:
                    Counter Object with sum of tags with accepted id per chunk
    """
    return list_of_dict_1 + list_of_dict_2


def top_10_tags():
    # Read xml file and load data to root

    root = read_xml()

    # Load data by chunks of 1000 data each
    data_chunks = chunkify(root, 1000)
    # Perform first step of map reduce
    mapped_chunks = mapped_chunks_top10_tags(data_chunks)
    # Perform second and las step, sum of all Counter objects generated by mapped_chunks function
    reduced = reduce(reducer_top10_tags, mapped_chunks)
    # Get top 10 tags with accepted answer id and display
    top_10 = reduced.most_common(10)
    logger.info("\t Top 10 tags with accepted answer id: ")
    for tag, count in top_10:
        logger.info(f'\t Tag: {tag}, Count: {count}')
    print()


def mapped_chunks_words_per_answercount(data_chunks):
    """
    Returns a map object with the dictionaries containg id, word count, answer count and word/answer count ratio
            Parameter chunks(generator):
                    chunk of data to process
            Returns:
                    mapped (map object): contains dictionaries objects with tags with accepted answer for each chunk
    """
    mapped = map(get_bodies_and_answer_counts, data_chunks)
    mapped = map(bodies_with_answer_count, mapped)
    mapped = map(count_words_in_body, mapped)
    mapped = map(generate_data_dict, mapped)
    return mapped


def reducer(data_dict_1, data_dict_2):
    """
    Returns the sum of all lists of Counter dictionaries to get total of each tag with an accepted answer per chunk

            Parametes:
                    data_dict_1 (dict): dictionary with data processed
                    data_dict_2 (dict): dictionary with data processed
            Returns:
                    data_dict_1 (dict) dictionary updated with data_dict_2
    """
    data_dict_1.update(data_dict_2)
    return data_dict_1


def display_post_wordanswer_ratio(data, post_id=1):
    """
    Display post id, word count, answer count and words/answers ratio

            Parameter:
                    data (dict): dictionary with data processed
    """
    try:
        logger.info(f'\t Post N{post_id} has: '
                    f'Word count {data[post_id]["Word count"]} - '
                    f'Answer count: {data[post_id]["Answer count"]} - '
                    f'Word/Answers ratio: {data[post_id]["Words per answers ratio"]}\n')

    except KeyError:
        logger.warning(' Post id is not in dictionary, post probably has not Answer count')


def word_per_answer_ratio():
    root = read_xml()
    # Load data by chunks of 4000 data each
    data_chunks = chunkify(root, 4000)
    # Perform first step of map reduce
    mapped_chunks = mapped_chunks_words_per_answercount(data_chunks)
    # Perform second step of map reduce
    reduced = reduce(reducer, mapped_chunks)
    # Display data requested
    display_post_wordanswer_ratio(reduced, post_id=6)


def percentage(data):
    """
    Returns Top 10 percentaje favorite question per user, and total favorite count
            Parameter:
                    data (Counter): contains all users id and its favorite quiestion count
            Returns:
                    data.most_common (list): top 10 user with porcentaje of favorite question
                    total_favorites (int): total favorite count
    """
    total_favorites = sum(data.values())

    for key, value in data.items():
        data[key] = value * 100 / total_favorites

    return data.most_common(10), total_favorites


def top_10_percentage_fav_question():
    root = read_xml()
    # Load data by chunks of 1000 data each
    data_chunks = chunkify(root, 1000)
    # Perform first step of map reduce
    mapped = map(get_user_favcount, data_chunks)
    # Perform second step of map reduce
    reduced = reduce(reducer, mapped)
    # Calculate percentage and retrive top 10
    top_10, fav_count = percentage(reduced)
    # Display data requested
    logger.info(f'\t Total Favorite Quiestion count: {fav_count}')
    for user_id, percent in top_10:
        logger.info(f'\t User Id {user_id} has {percent:.{2}f}% Favorite questions')


# Run main script
if __name__ == '__main__':
    top_10_tags()
    word_per_answer_ratio()
    top_10_percentage_fav_question()
